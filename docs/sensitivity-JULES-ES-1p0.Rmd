---
title: "Sensitivity Analysis Earth System configuration of JULES"
author: "Doug McNeall"
date: "09/08/2021"
output: 
    html_notebook:
        toc: true
        toc_float: true
        toc_depth: 3
        number_sections: true
---


## Preliminaries
Load libraries, functions and data.

```{r, echo = FALSE, message = FALSE, warning=FALSE, results = 'hide'}
# Load helper functions
  
knitr::opts_chunk$set(fig.path = "figs/", echo = FALSE, message = FALSE, warnings = FALSE)

# load helper functions, data and do preliminary processing of the ensemble.
source('JULES-ES-1p0-common.R')
```


```{r}
# Helper functions

# rotate a matric 90 degrees clockwise for plotting
rotate <- function(x) t(apply(x, 2, rev))



sensvar = function(oaat_pred, n, d){
  # Calculate variance as a global sensitivity meansure
  out = rep(NA,d)
  for(i in 1:d){
    ix = seq(from = ((i*n) - (n-1)), to =  (i*n), by = 1)
    out[i] = var(oaat_pred$mean[ix])
  }
  out
}


twoStep_sens <- function(X, y, n=21, predtype = 'UK', nugget=NULL, nuggetEstim=FALSE, noiseVar=NULL, seed=NULL, trace=FALSE, maxit=100,
                        REPORT=10, factr=1e7, pgtol=0.0, parinit=NULL, popsize=100){
  # Sensitivity analysis with twoStep emulator. 
  # Calculates the variance of the output varied one at a time across each input.
  d = ncol(X)
  X_norm <- normalize(X)
  X_oaat <- oaat_design(X_norm, n, med = TRUE)
  colnames(X_oaat) = colnames(X)
  
  twoStep_em = twoStep_glmnet(X=X, y=y, nugget=nugget, nuggetEstim=nuggetEstim, noiseVar=noiseVar,
                              seed=seed, trace=trace, maxit=maxit,
                              REPORT=REPORT, factr=factr, pgtol=pgtol,
                              parinit=parinit, popsize=popsize)
  
  oaat_pred = predict(twoStep_em$emulator, newdata = X_oaat, type = predtype)
  
  sens = sensvar(oaat_pred = oaat_pred, n=n, d=d)
  out = sens
  out
}



oaatSensvarKm <- function(X, y, n = 21, formula = ~., predtype = 'UK', ...){
  # one-at-a-time sensitivity summary with a standard dicekriging emulator
  
  d = ncol(X)
  X_norm <- normalize(X)
  X_oaat <- oaat_design(X_norm, n, med = TRUE)
  colnames(X_oaat) = colnames(X)
  

  em <- km(formula = formula, design = X, response = y, ...)
  
  oaat_pred = predict(em, newdata = X_oaat, type = predtype)
  
  sens = sensvar(oaat_pred = oaat_pred, n=n, d=d)
  out = sens
  out
  
}


oaatSensvarSummaryPlot <- function(oat_sens_mat){
  
  # relies on rotate(), fields,  which need sorting for transfer to package
  
  ynames <- rownames(oat_sens_mat)
  xnames <- colnames(oat_sens_mat)
  
  normsens <- normalize(t(oat_sens_mat))
  normsens_mean <- apply(normsens,1, mean)
  
  sort_ix <- sort(normsens_mean, decreasing = TRUE, index.return = TRUE)
  
  par(mar = c(15,12,5,1), mfrow = c(1,2))
  
  layout(matrix(c(1,1,2), ncol = 3, nrow = 1))
  
  image(rotate(normsens[sort_ix$ix, ]), axes = FALSE, col = blues)
  
  axis(1, at = seq(from = 0, to = 1, length.out = length(ynames)), labels = ynames, las = 3, cex.axis = 1.2)
  axis(2, at = seq(from = 1, to = 0, length.out = length(xnames)), labels = xnames[sort_ix$ix], las = 1, cex.axis = 1.2)
  mtext('One-at-a-time sensitivity', side = 3, adj = 0, line = 2, cex = 1)
  
  lab_ix <- (1:length(xnames)) - 0.5
  
  par(yaxs = 'i', mar = c(15,1,5,5))
  plot(rev(normsens_mean[sort_ix$ix]), lab_ix, xlab = 'mean oaat variance (normalized)', ylab = '', ylim = c(0,length(xnames)), type = 'n', yaxt = 'n')
  abline(h = lab_ix, col = 'grey', lty = 'dashed')
  points( rev(normsens_mean[sort_ix$ix]),lab_ix, col = zissou5[1], pch = 19, cex = 1.5)
  
  image.plot(legend.only = TRUE,
             zlim = c(0,1),
             col = blues,
             legend.args = list(text = 'Relative sensitivity', side = 3, line = 1),
             horizontal = TRUE
  )
  
}

```

```{r}
# We're just interested in the "sum" (global totals) data, not the "mean" (global means) data
y_names_sum <- c('nbp_lnd_sum', 'fLuc_lnd_sum', 'npp_nlim_lnd_sum', 'cSoil_lnd_sum',
            'cVeg_lnd_sum', 'landCoverFrac_lnd_sum', 'fHarvest_lnd_sum',
            'lai_lnd_sum', 'rh_lnd_sum', 'treeFrac_lnd_sum', 'c3PftFrac_lnd_sum', 
            'c4PftFrac_lnd_sum', 'shrubFrac_lnd_sum', 'baresoilFrac_lnd_sum')
```



# Sensitivity at level1a constraint (f0_io and b_wl_io truncated)
Define constraint level 1a as those members that run, and have F0_io <0.9 & b_wl_io > 0.15 (normalised).

## Modern value sensitivity

```{r}
if (file.exists("oaat_level1a_Y.rdata")) {
  load("oaat_level1a_Y.rdata")
} else {
  
oat_var_sensmat_level1a_Y <- matrix(NA, nrow = length(y_names_sum), ncol = ncol(X_level1a))

for(i in 1:length(y_names_sum)){
  
  yname <- y_names_sum[i]
  y <- Y_level1a[, yname]
  oat <- oaatSensvarKm(X = X_level1a, y = y)
  oat_var_sensmat_level1a_Y[i, ] <- oat
}

save(y_names_sum, oat_var_sensmat_level1a_Y, file = "oaat_level1a_Y.rdata")
}

rownames(oat_var_sensmat_level1a_Y) <- y_names_sum
colnames(oat_var_sensmat_level1a_Y) <- colnames(X_level1a)

#normsens_level1a_Y <- normalize(t(oat_var_sensmat_level1a_Y))

```


```{r, fig.width = 7, fig.height = 8}

#pdf(file = 'figs/oat_var_sensmat_level1a_Y.pdf', width = 7, height = 8)
oaatSensvarSummaryPlot(oat_var_sensmat_level1a_Y)

#dev.off()

```

## Anomaly (Change 1850 - 2013) sensitivities

```{r}
if (file.exists("oaat_level1a_YAnom.rdata")) {
  load("oaat_level1a_YAnom.rdata")
} else {
  
oat_var_sensmat_level1a_YAnom <- matrix(NA, nrow = length(y_names_sum), ncol = ncol(X_level1a))

for(i in 1:length(y_names_sum)){
  
  yname <- y_names_sum[i]
  y <- YAnom_level1a[, yname]
  oat <- oaatSensvarKm(X = X_level1a, y = y)
  oat_var_sensmat_level1a_YAnom[i, ] <- oat
}

save(y_names_sum, oat_var_sensmat_level1a_YAnom, file = "oaat_level1a_YAnom.rdata")
}


rownames(oat_var_sensmat_level1a_YAnom) <- y_names_sum
colnames(oat_var_sensmat_level1a_YAnom) <- colnames(X_level1a)

# Normalise sensitivities
#normsens_level1a_YAnom <- normalize(t(oat_var_sensmat_level1a_YAnom))

```


```{r, fig.width = 7, fig.height = 8}

#pdf(file = 'figs/oat_var_sensmat_level1a_YAnom.pdf', width = 7, height = 8)
oaatSensvarSummaryPlot(oat_var_sensmat_level1a_YAnom)
#dev.off()

```


### Ranking sensitivity of the parameters.

```{r}

oaatSensvarRank <- function(oat_sens_mat){
  
  ynames <- rownames(oat_sens_mat)
  xnames <- colnames(oat_sens_mat)
  
  normsens <- normalize(t(oat_sens_mat))
  normsens_mean <- apply(normsens,1, mean)
  
  rank <- rank(-normsens_mean)
  
  
  return(list(mean = normsens_mean, rank = rank))
  
}


Y_level1a_sensrank <- oaatSensvarRank(oat_var_sensmat_level1a_Y)
YAnom_level1a_sensrank <- oaatSensvarRank(oat_var_sensmat_level1a_YAnom)

  
sens_ranks <- cbind(Y_level1a_sensrank$rank, YAnom_level1a_sensrank$rank )
colnames(sens_ranks) <- c('modern_value', 'anomaly')

min_rank <- apply(sens_ranks,1, min)

all_ranks <- cbind(sens_ranks, min_rank)

plot(sens_ranks[,1], sens_ranks[,2], xlab = 'modern value rank', ylab = 'anomaly rank')


rank_ix <- sort(min_rank, decreasing = FALSE, index.return = TRUE)

# All ranks is the table of rankings, with min_rank being the highest ranking
all_ranks[rank_ix$ix, ]
  
```




## One-at-a-time sensitivity analysis of constraining variables for understanding model response
"Constraining variables" being those we use to constrain the model (npp, nbp, cSoil and cVeg).
It's hard to maintain a high vegetation carbon in particular.  

Further idea: What parameter values might you choose to do this, and what might be the trade-offs you have to make?


```{r}
fit_list_const_level1a <- createKmFitList(X = X_level1a, Y = Y_const_level1a_scaled)

```


```{r}
# Check that oatSensVar and the plotting make sense

oaat_sens_cVeg <- oaatSensvarKm(X = X_level1a, y = Y_const_level1a_scaled[,"cVeg_lnd_sum"])

X_oaat_level1a <- oaat_design(X_level1a, n=21, med = TRUE)

colnames(X_oaat_level1a) = colnames(X)

y_oaat <- predict.km(fit_list_const_level1a[[4]], newdata = X_oaat_level1a, type = 'UK')

```


First, what parameters affect vegetation carbon and how? How sure are we about that?

```{r, fig.width = 8, fig.height = 10}


oaatLinePlot(X_oaat = X_oaat_level1a, y_oaat_mean = y_oaat$mean, y_oaat_sd = y_oaat$sd, 
             n_oaat = 21,nr = 6, nc = 6) 


```



```{r}

Y_oaat_const_level1a_scaled <- matrix(ncol = ncol(Y_const_level1a_scaled), nrow = nrow(X_oaat_level1a))

for(i in 1:ncol(Y_const_level1a_scaled)){

  y_oaat <- predict.km(fit_list_const_level1a[[i]], newdata = X_oaat_level1a, type = 'UK')
  Y_oaat_const_level1a_scaled[,i] <- y_oaat$mean
}

```


What might be the trade-offs for a high (or accurate) vegetation carbon? are they acceptable? Plot the oaat sensitivity of the other 3 outputs we're calibrating on. 

```{r, fig.width=10, fig.height = 10}
Y_oaat_const_level1a_scaled_norm <- normalize(Y_oaat_const_level1a_scaled)

        oaatLinePlotMulti <- function(X_oaat, Y_oaat, n_oaat, nr, nc, cols, ...){
  
  
  
  
          par(mfrow = c(nr,nc), oma = c(0.1,0.1,3,0.1), mar = c(2,2,3,1))
  
          for(i in 1:ncol(X_oaat)){
            ix <- seq(from = ((i*n_oaat) - (n_oaat-1)), to =  (i*n_oaat), by = 1)
    
            plot(X_oaat[ix,i], Y_oaat[ix,1],
                 xlim = c(0,1), ylim = c(0,1),
                 xlab = colnames(X_oaat)[i],
                 type= 'n',
                 bty = 'n')
  
            for(j in 1:ncol(Y_oaat)){
              lines(X_oaat[ix,i], Y_oaat[ix, j], lty = 'solid', col = cols[j], ...)
              mtext(colnames(X_oaat)[i], side = 3, line = 0.5)
  
            }
  
          }
    
        }

#pdf(file = 'figs/Y_oaat_const_level1a_scaled_norm.pdf', width = 10, height = 10)
oaatLinePlotMulti(X_oaat = X_oaat_level1a, Y_oaat = Y_oaat_const_level1a_scaled_norm ,  n_oaat = 21, nr = 6, nc = 6,
                  lwd = 3, col = cbPal[c(1,2,6,8)])
  
reset()
legend('top', c('nbp', 'npp', 'csoil', 'cveg'), col = cbPal[c(1,2,6,8)], lty = 'solid', lwd = 3, horiz = TRUE)
#dev.off()

```





```{r}

knit_exit()

```




```{r, fig.height = 8, fig.width = 4}

# Summarise the sensitivity summaries per parameter

normsens_mean_Y <- apply(normsens_level1a_Y ,1, mean)
normsens_mean_YAnom <- apply(normsens_level1a_YAnom ,1, mean)
  
sort_ix <- sort(normsens_mean_Y, decreasing = FALSE, index.return = TRUE)

dotchart(normsens_mean_Y[sort_ix$ix], labels = colnames(X_level1a)[sort_ix$ix], bg = zissou5[5] , xlim = c(0,0.8), pch = 19)
points(normsens_mean_YAnom[sort_ix$ix], 1:32, col = zissou5[1], pch = 19)
         
dotchart(normsens_mean_Y, labels = colnames(X_level1a), bg = zissou5[5] , xlim = c(0,0.8), pch = 19)
points(normsens_mean_YAnom, 1:32, col = zissou5[1], pch = 19)


#dotchart(data$sold, pch = 21, labels = data$month, bg = "green",
#         pt.cex = 1.5, xlim = range(data$expected, data$sold) + c(-2, 2))
#points(data$expected, 1:nrow(data), col = "red", pch = 19, cex = 1.5)

```




```{r, fig.width = 7, fig.height = 8}

sort_ix <- sort(normsens_mean_Y, decreasing = TRUE, index.return = TRUE)
# Now put the charts together
par(mar = c(15,12,5,1), mfrow = c(1,2))

layout(matrix(c(1,1,2), ncol = 3, nrow = 1))

image(rotate(normsens_level1a_Y[sort_ix$ix, ]), axes = FALSE, col = blues)

axis(1, at = seq(from = 0, to = 1, length.out = length(y_names_sum)), labels = y_names_sum, las = 3, cex.axis = 1.2)
axis(2, at = seq(from = 1, to = 0, length.out = p), labels = colnames(X_level1a)[sort_ix$ix], las = 1, cex.axis = 1.2)
mtext('One-at-a-time sensitivity, variance across level 1a ensemble', side = 3, adj = 0, line = 2, cex = 1)

lab_ix <- 0.5:31.5

par(yaxs = 'i', mar = c(15,1,5,5))
plot(rev(normsens_mean_Y[sort_ix$ix]), lab_ix, xlab = 'mean oaat variance (normalized)', ylab = '', ylim = c(0,32), type = 'n', yaxt = 'n')
abline(h = 0.5:31.5, col = 'grey', lty = 'dashed')
points( rev(normsens_mean_Y[sort_ix$ix]),lab_ix, col = zissou5[1], pch = 19, cex = 1.5)

image.plot(legend.only = TRUE,
           zlim = c(0,1),
           col = blues,
           legend.args = list(text = 'Relative sensitivity', side = 3, line = 1),
           horizontal = TRUE
)

```


```{r, fig.width = 7, fig.height = 8}

sort_ix <- sort(normsens_mean_YAnom, decreasing = TRUE, index.return = TRUE)
# Now put the charts together
par(mar = c(15,12,5,1), mfrow = c(1,2))

layout(matrix(c(1,1,2), ncol = 3, nrow = 1))

image(rotate(normsens_level1a_YAnom[sort_ix$ix, ]), axes = FALSE, col = blues)

axis(1, at = seq(from = 0, to = 1, length.out = length(y_names_sum)), labels = y_names_sum, las = 3, cex.axis = 1.2)
axis(2, at = seq(from = 1, to = 0, length.out = p), labels = colnames(X_level1a)[sort_ix$ix], las = 1, cex.axis = 1.2)
mtext('One-at-a-time sensitivity, variance across level 1a ensemble', side = 3, adj = 0, line = 2, cex = 1)

lab_ix <- 0.5:31.5

par(yaxs = 'i', mar = c(15,1,5,5))
plot(rev(normsens_mean_YAnom[sort_ix$ix]), lab_ix, xlab = 'mean oaat variance (normalized)', ylab = '', ylim = c(0,32), type = 'n', yaxt = 'n')
abline(h = 0.5:31.5, col = 'grey', lty = 'dashed')
points( rev(normsens_mean_YAnom[sort_ix$ix]),lab_ix, col = zissou5[1], pch = 19, cex = 1.5)

image.plot(legend.only = TRUE,
           zlim = c(0,1),
           col = blues,
           legend.args = list(text = 'Relative sensitivity', side = 3, line = 1),
           horizontal = TRUE
)

```

```{r}



```



```{r, fig.width = 12, fig.height = 12}

p <- ncol(X_level1a)

y_level1a <- Y_level1a[,'npp_nlim_lnd_sum']

par(mfrow = c(5,7), mar = c(3,1,3,1))
for(i in 1:p){
  plot(X_level1a[,i], y_level1a, xlab = '', ylab = '', main = colnames(X_level1a)[i], xlim = c(0,1))
}

```

# comparision of sensitivities level1 vs level1a
With b_wl truncated, we can clearly see the sensitivities change.

```{r, fig.width= 10, fig.height = 6}
# normalize the sensitivity matrix
colnames(oat_var_sensmat_level1a_Y) <- colnames(X_level1a)
rownames(oat_var_sensmat_level1a_Y) <- y_names_sum

#test <- normalize(t(oat.var.sensmat))

#image(test)
#par()
heatmap(oat_var_sensmat_level1a_Y, Rowv = NA, Colv = NA, mar = c(10,10), scale = 'row')
heatmap(oat_var_sensmat_level1a_Y, mar = c(10,10), scale = 'row')

```


```{r, fig.width =12, fig.height = 7}

normsens_level1a_Y <- normalize(t(oat_var_sensmat_level1a_Y))

par(mar = c(12,12,5,2))
image(normsens_level1a_Y, axes = FALSE, col = blues)
axis(1, at = seq(from = 0, to = 1, length.out = p), labels = colnames(X_level1a), las = 2)
axis(2, at = seq(from = 0, to = 1, length.out = length(y_names_sum)), labels = y_names_sum, las = 1)
mtext('One-at-a-time sensitivity, variance across level 1a ensemble', side = 3, adj = 0, line = 2, cex = 1.8)

```



```{r}
# This fails for "cVeg_lnd_sum"
# The result will be that some of the columns are repeated.

if (file.exists("oaat_YAnom.rdata")) {
  load("oaat_YAnom.rdata")
} else {

oat_var_sensmat_YAnom <- matrix(NA, nrow = length(y_names_sum), ncol = ncol(X_level1))

for(i in 1:length(y_names_sum)){
  
  yname <- y_names_sum[i]
  y <- YAnom_level1[, yname]
  try(oat <- twoStep_sens(X = X_level1, y = y))
  oat_var_sensmat_YAnom[i, ] <- oat
}

save(y_names_sum, oat_var_sensmat_YAnom, file = "oaat_YAnom.rdata")

}
```



```{r, fig.width= 10, fig.height = 6}
# normalize the sensitivity matrix
colnames(oat_var_sensmat_YAnom) <- colnames(X_level1)
rownames(oat_var_sensmat_YAnom) <- y_names_sum

#test <- normalize(t(oat.var.sensmat))

#image(test)
#par()
heatmap(oat_var_sensmat_YAnom, Rowv = NA, Colv = NA, mar = c(10,10), scale = 'row')
heatmap(oat_var_sensmat_YAnom, mar = c(10,6), scale = 'row')

```


```{r, fig.width =12, fig.height = 7}

normsens_YAnom <- normalize(t(oat_var_sensmat_YAnom))

par(mar = c(12,12,5,2))
image(normsens_YAnom, axes = FALSE, col = blues)
axis(1, at = seq(from = 0, to = 1, length.out = p), labels = colnames(X_level1), las = 2)
axis(2, at = seq(from = 0, to = 1, length.out = length(y_names_sum)), labels = y_names_sum, las = 1)
mtext('One-at-a-time sensitivity, variance of historical change across level 1 ensemble', side = 3, adj = 0, line = 2, cex = 1.8)

```


# Plot both sensitivity matrices on top of one another.
It looks as though both the absolute value and the change over time are controlled by the same parameters.
```{r, fig.width =12, fig.height = 12}
par(mfrow = c(2,1), mar = c(12,12,5,2))

image(normsens_Y, axes = FALSE, col = blues)
axis(1, at = seq(from = 0, to = 1, length.out = p), labels = colnames(X_level1), las = 2)
axis(2, at = seq(from = 0, to = 1, length.out = length(y_names_sum)), labels = y_names_sum, las = 1)
mtext('One-at-a-time sensitivity, variance of historical change across level 1 ensemble', side = 3, adj = 0, line = 2, cex = 1.8)


image(normsens_YAnom, axes = FALSE, col = blues)
axis(1, at = seq(from = 0, to = 1, length.out = p), labels = colnames(X_level1), las = 2)
axis(2, at = seq(from = 0, to = 1, length.out = length(y_names_sum)), labels = y_names_sum, las = 1)
mtext('One-at-a-time sensitivity, variance of historical change across level 1 ensemble', side = 3, adj = 0, line = 2, cex = 1.8)


```


Need Y and Yanom sensitivities at level 1a

```{r}
# This fails for "cVeg_lnd_sum"
# The result will be that some of the columns are repeated.

if (file.exists("oaat_level1a_YAnom.rdata")) {
  load("oaat_level1a_YAnom.rdata")
} else {

oat_var_sensmat_level1a_YAnom <- matrix(NA, nrow = length(y_names_sum), ncol = ncol(X_level1a))

for(i in 1:length(y_names_sum)){
  
  yname <- y_names_sum[i]
  y <- YAnom_level1a[, yname]
  try(oat <- twoStep_sens(X = X_level1a, y = y))
  oat_var_sensmat_level1a_YAnom[i, ] <- oat
}

save(y_names_sum, oat_var_sensmat_level1a_YAnom, file = "oaat_level1a_YAnom.rdata")

}
```





## twoStep sensitivity analysis

It seems clear from the emulator testing that the twoStep emulator in't performing any better than the regular km emulator.  
Given that, this section probably shouldn't be in the main analysis.

```{r, warning=FALSE, message = FALSE}

if (file.exists("oat_twostep.rdata")) {
  load("oat_twostep.rdata")
} else {
oat_test <- twoStep_sens(X = X_level1, y = y_level1)


save(oat_test, file = "oat_twostep.rdata")
}

```


```{r}

if (file.exists("oaat_Y.rdata")) {
  load("oaat_Y.rdata")
} else {
  
  
oat_var_sensmat_Y <- matrix(NA, nrow = length(y_names_sum), ncol = ncol(X_level1))

for(i in 1:length(y_names_sum)){
  
  yname <- y_names_sum[i]
  y <- Y_level1[, yname]
  oat <- twoStep_sens(X = X_level1, y = y)
  oat_var_sensmat_Y[i, ] <- oat
}

save(y_names_sum, oat_var_sensmat_Y, file = "oaat_Y.rdata")
}
```



## Sensitivity at level1 constraint (truncated f0_io)
bwl_io becomes very influential across a number of variables

```{r, fig.width= 10, fig.height = 6}
# normalize the sensitivity matrix
colnames(oat_var_sensmat_Y) <- colnames(X_level1)
rownames(oat_var_sensmat_Y) <- y_names_sum

#test <- normalize(t(oat.var.sensmat))

#image(test)
#par()
heatmap(oat_var_sensmat_Y, Rowv = NA, Colv = NA, mar = c(10,10), scale = 'row')
heatmap(oat_var_sensmat_Y, mar = c(10,10), scale = 'row')

```


```{r, fig.width =12, fig.height = 7}


normsens_Y <- normalize(t(oat_var_sensmat_Y))

par(mar = c(12,12,5,2))
image(normsens_Y, axes = FALSE, col = blues)
axis(1, at = seq(from = 0, to = 1, length.out = p), labels = colnames(X_level1), las = 2)
axis(2, at = seq(from = 0, to = 1, length.out = length(y_names_sum)), labels = y_names_sum, las = 1)
mtext('One-at-a-time sensitivity, variance across level 1 ensemble', side = 3, adj = 0, line = 2, cex = 1.8)

```


