---
title: "Sensitivity analysis and constraint of the parameter space of Earth System configuration of JULES"
author: "Doug McNeall"
date: "24/03/2021"
output: 
    html_notebook:
        toc: true
        toc_float: true
        toc_depth: 3
        number_sections: true
---

# Introduction
Update of explore-JULES-ES-1p0.Rmd that uses the new packages and functions

We build and test gaussian process emulators, perform a sensitivity analyis, and constrain the input space of Jules.


Andy thinks there might be mileage in analysing the atmospheric growth, which is here.
/home/h01/hadaw/Research/ES_PPE/Oct20
  
At the moment, this vignette is hampered by the fact that emulators are failing on a few of the outputs which represent change over the historical period. The emulator is fine for predicting absolute values in the modern period.

Andy would like to see timeseries of:
cVeg, cSoil and nbp, npp in GtC and GtC/yr.

## Preliminaries
Load libraries, functions and data.

```{r, echo = FALSE, message = FALSE, warning=FALSE, results = 'hide'}
# Load helper functions

knitr::opts_chunk$set(fig.path = "figs/", echo = FALSE, message = FALSE, warnings = FALSE)

# load helper functions, data and do preliminary processing of the ensemble.
source('JULES-ES-1p0-common.R')
```



## Carbon budget data

[Section 2.5 in Friedlingstein et al.](https://essd.copernicus.org/articles/12/3269/2020/#section2) describes how the land carbon sink is estimated.
```{r, historical-carbon-budget, warning = FALSE, fig.width = 10, fig.height = 10}

#pdf(file = 'carbon_budget.pdf', width = 10, height = 8)
# Question: How closely should our model match this curve? Which output?
# (My guess is 'Total Land Carbon anomaly')
historical_carbon_budget <- read_excel('Global_Carbon_Budget_2020v1.0.xlsx', sheet = "Historical Budget", skip = 15, n_max = 270)

par(mfrow = c(3,2))
ylim = c(-1, 6)


land_sink_net <- historical_carbon_budget$`land sink` - historical_carbon_budget$`land-use change emissions`

plot(historical_carbon_budget$Year, historical_carbon_budget$`fossil emissions excluding carbonation`, main = 'fossil emissions excluding carbonation', ylab = '',
     type = 'l', bty = 'n', ylim = ylim)

plot(historical_carbon_budget$Year, historical_carbon_budget$`land sink`, main = 'land sink', ylab = '', type = 'l', bty = 'n', ylim = ylim)

lines(historical_carbon_budget$Year, land_sink_net, col = 'red')

legend('topleft', legend = 'land sink - land use change emissions', col = 'red', lty = 'solid')

plot(historical_carbon_budget$Year, historical_carbon_budget$`land-use change emissions`, main = 'land use change emissions',
     ylab = '', type = 'l', bty = 'n', ylim = ylim)

plot(historical_carbon_budget$Year, historical_carbon_budget$`atmospheric growth`, main = 'atmospheric growth', ylab = '',
     type = 'l', bty = 'n', ylim = ylim)


plot(historical_carbon_budget$Year, historical_carbon_budget$`ocean sink`, main = 'ocean sink', type = 'l', bty = 'n', ylim = ylim)

plot(historical_carbon_budget$Year, historical_carbon_budget$`budget imbalance`, main = 'budget imbalance', ylab = '', type = 'l', bty = 'n', ylim = ylim)

#dev.off()
```


### Variables available for analysis

Load a single ensemble member to examine contents
```{r, load-output-ensemble}
ensmember <- 'P0000/'
subdir <- 'stats/'

floc <- paste0(ensloc,ensmember,subdir)
fn <- 'JULES-ES-1p0_P0000_Annual_global.nc'

# test file
nc <- nc_open(paste0(floc,fn))

# What variables are in the file? 
varlist <- nc.get.variable.list(nc)

for(i in 1:length(varlist)){
  
  var <- varlist[i]
  print(var)
  print(ncatt_get(nc,var,"long_name")[[2]])
}
```


## Plot timeseries of aggregated global timeseries 


```{r plot-carbon-cycle-timeseries-primary, fig.width = 10, fig.height = 12}

#pdf(file = 'figs/plot-carbon-cycle-timeseries-primary-1.pdf', width = 10, height = 12)
par(mfrow= c(3,4), las = 1)

plotcol <- c(makeTransparent('black', 70))

ylim = range(c(npp_ens[,1], npp_ens[,164]))
matplot(years, t(npp_ens), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'GtC', main = 'NPP', xlab = '',
        bty = 'n')

ylim = range(c(cSoil_ens[,1], cSoil_ens[,164]))
matplot(years, t(cSoil_ens), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'GtC', main = 'Soil Carbon',xlab = '',
        bty = 'n')

ylim = range(c(cVeg_ens[,1], cVeg_ens[,164]))
matplot(years, t(cVeg_ens), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'GtC', main = 'Vegetation Carbon',xlab = '',
        bty = 'n')

ylim = range(total_land_carbon_ens)
matplot(years, t(total_land_carbon_ens), type = 'l', lty = 'solid',ylim = ylim, col = plotcol, 
        ylab = 'GtC', main = 'Total Land Carbon',xlab = '',
        bty = 'n')


ylim = range(lai_lnd_mean_ens)
matplot(years, t(lai_lnd_mean_ens), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'LAI', main = 'Leaf area index',xlab = '',
        bty = 'n')

ylim = range(treeFrac_lnd_mean_ens)
matplot(years, t(treeFrac_lnd_mean_ens), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'fraction', main = 'Tree fraction',xlab = '',
        bty = 'n')

ylim = range(shrubFrac_lnd_mean_ens)
matplot(years, t(shrubFrac_lnd_mean_ens ), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'fraction', main = 'Shrub fraction',xlab = '',
        bty = 'n')

ylim = c(0,100)
matplot(years, t(baresoilFrac_lnd_mean_ens ), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'fraction', main = 'bare soil fraction',xlab = '',
        bty = 'n')

ylim = c(-10, 10)
matplot(years, t(nbp_ens), type = 'l', lty = 'solid',ylim = ylim, col = plotcol, 
        ylab = 'GtC', main = 'NBP', xlab = '',
        bty = 'n')
  
ylim = range(rh_lnd_sum_ens)
matplot(years, t(rh_lnd_sum_ens), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'GtC/year', main = 'Heterotrophic Respiration', xlab = '',
        bty = 'n')

ylim = range(fLuc_lnd_sum_ens)
matplot(years, t(fLuc_lnd_sum_ens), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'GtC/year', main = 'Land use change emissions', xlab = '',
        bty = 'n')

ylim = range(fHarvest_lnd_sum_ens)
matplot(years, t(fHarvest_lnd_sum_ens), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'GtC/year', main = 'Harvest C flux to atmosphere', xlab = '',
        bty = 'n')

#dev.off()

```


```{r plot-carbon-cycle-anomaly-timeseries, fig.width = 9, fig.height = 6}

par(mfrow= c(1,4), las = 1)

# ylim = range(-10, 10)
#matplot(years, t(nbp_ens_anom), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
#        ylab = 'NBP sum Anomaly', main = 'NBP Anomaly',
#        bty = 'n')

ylim = range(c(npp_ens_anom[,1], npp_ens_anom[,164]))
matplot(years, t(npp_ens_anom), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'NPP sum Anomaly', main = 'NPP Anomaly',
        bty = 'n')

ylim = range(c(cSoil_ens_anom[,1], cSoil_ens_anom[,164]))
matplot(years, t(cSoil_ens_anom), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'GtC', main = 'Soil Carbon Anomaly',
        bty = 'n')

ylim = range(c(cVeg_ens_anom[,1], cVeg_ens_anom[,164]))
matplot(years, t(cVeg_ens_anom), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'GtC', main = 'Vegetation Carbon Anomaly',
        bty = 'n')

ylim = range(total_land_carbon_anom)
matplot(years, t(total_land_carbon_anom), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'GtC', main = 'Total Land Carbon Anomaly',
        bty = 'n')


```



## Where did the model fail to run?
("probability of run failure" Could be an interesting project - logit transformation for probability of run failure? Some other ML like SVM?

There are clear run failure thresholds in the parameters rootd_ft_io and lai_max, and quite strong visual indications that a_wl_io and bio_hum_cn matter.


NEXT, histograms of failure with the LHS value
```{r run-failure-pairs, fig.width = 11, fig.height = 11}

# NB, plotting the inverse of this doesn't give you much information
#pdf(file = 'figs/run-failure-pairs.pdf', width = 11, height = 11)
#simple way
#par(xpd = TRUE)
pairs(X_nlevel0, 
      xlim = c(0,1), ylim = c(0,1),
      labels = 1:d,
      col = makeTransparent('red', 150),
      gap = 0,
      pch = 20,
      xaxt ='n', yaxt = 'n',
      lower.panel = NULL,
      oma = c(0.5, 0.5, 0.5, 0.5))

reset()

legend('left', legend = paste(1:d, colnames(lhs)), cex = 1.2, bty = 'n')

#dev.off()

```


```{r, fig.width = 12, fig.height = 8}

#pdf(file = 'figs/run-failure-hists.pdf', width = 12, height = 8)

par(mfrow = c(4, 8), mar = c(4,3,2,1))

for(i in 1:d){
  
  hist(X_nlevel0[,i], xlim = c(0,1), breaks = seq(from=0, to = 1, by = 0.1), col = 'grey', main = '', ylim = c(0,9),
       border = 'white', xlab = colnames(X_nlevel0)[i], ylab = '', las = 1, cex.lab = 1.5)
}

#dev.off()

```

Could try an SVM, logistic regression or similar.


## Testing Gaussian Process emulators


### NPP as a test
First, use mean NPP as an example. How does NPP respond to each parameter? NAs are removed, but zero values are still included.

```{r plot-npp-modern, fig.width = 12, fig.height = 12}

y_level0 <- Y_level0[,'npp_nlim_lnd_sum']

par(mfrow = c(5,7), mar = c(3,1,3,1), oma = c(1,1,5,1))
for(i in 1:p){
  plot(X_level0[,i], y_level0, xlab = '', ylab = '', main = colnames(X_level0)[i])
}
mtext('NPP', outer = TRUE, side = 3, cex = 2, line = 2)

```


```{r plot-npp-change, fig.width = 12, fig.height = 12}

yanom_level0 <- YAnom_level0[,'npp_nlim_lnd_sum']

par(mfrow = c(5,7), mar = c(3,1,3,1), oma = c(1,1,5,1))
for(i in 1:p){
  plot(X_level0[,i], yanom_level0, xlab = '', ylab = '', main = colnames(X_level0)[i])
}
mtext('NPP change over time', outer = TRUE, side = 3, cex = 2, line = 2)

```


## Relationship between modern NPP and change since 1850.

Some outputs (e.g fLuc, fHarvest) have an almost perfect 1:1 relationship between modern value and change, some  (nbp, npp, treeFrac) quite or moderately strong, and some (csoil, cveg) very weak or non-existant.
```{r npp-modern-vs-change, fig.width = 12, fig.height = 8}

par(mfrow = c(4,7), mar = c(3,1,3,1), oma = c(4,5,1,1))

pdash <- ncol(Y_level0)

for(i in 1:pdash){
  
  y_level0 <- Y_level0[,i]
  yanom_level0 <- YAnom_level0[,i]
  
  plot(y_level0, yanom_level0, xlab = '', ylab = '', main = colnames(Y_level0)[i])
}

mtext(text = 'Modern value', side = 1, line = 2, outer = TRUE, cex = 2)
mtext(text = 'Change', side = 2, line = 2, outer = TRUE, cex = 2)

```



## A clear threshold in the F0 parameter for NPP
It appears that this ensemble is less "clear cut" in having an output that clearly distinguishes between "failed" (or close to it), and "not failed".

Having said that, having an F0 over a threshold seems to kill the carbon cycle, as before. Here, we've set a threshold of 0.9 (on the normalised scale) for F0, and we remove members of the ensemble with a larger F0 than that when we build emulators.

```{r, fig.width = 6, fig.height = 8}

par(mfrow = c(2,1))
plot(lhs$f0_io, datmat[, 'npp_nlim_lnd_sum'], main = 'Multiplication factor', xlab = 'f0_io', ylab = 'NPP sum')
plot(X_level0[,'f0_io'], Y_level0[, 'npp_nlim_lnd_sum'], xlab = 'f0_io', main = 'Normalized', ylab = 'NPP sum')
abline(v = 0.9)

```




```{r failure-pairs, fig.width=12, fig.height=12, fig.path='figs/', dev=c('png', 'pdf')}


low_npp_ix <- which(Y[,'npp_nlim_lnd_sum'] < 1e5)
# code from https://stackoverflow.com/questions/28182872/how-to-use-different-sets-of-data-in-lower-and-upper-panel-of-pairs-function-in


#X <- matrix(runif(300), ncol=3)
#Y <- matrix(c(sort(runif(100, 0, 10)), 
#              sort(runif(100, 0, 10)), 
#              sort(runif(100, 0, 10))), ncol=3)

#pdf(file = 'figs/run-failure-pairs.pdf', width = 12, height = 10)
x1 <- X[low_npp_ix, ]
x2 <- X_nlevel0

XY <- rbind(x1, x2)


pairs(XY,
      lower.panel=function(x, y, ...) {
        Xx <- x[seq_len(nrow(x1))] # corresponds to X subset
        Xy <- y[seq_len(nrow(x1))] # corresponds to X subset
        #usr <- par("usr"); on.exit(par(usr))
        #par(usr = c(range(x1[, -ncol(x1)]), range(x1[, -1]))) # set up limits
        points(Xx, Xy, col = zblue, pch = 19, cex = 0.8)
       # if(par('mfg')[2] == 1) axis(2) # if left plot, add left axis
        #if(par('mfg')[1] == ncol(x1)) axis(1) # if bottom plot add bottom axis
      }, 
      upper.panel=function(x, y, ...) {
        Yx <- x[(nrow(x1) + 1):length(x)] # Y subset
        Yy <- y[(nrow(x1) + 1):length(y)] # Y subset
        
        #cntr <- outer(Yx, Yx, FUN='*') # arbitrary function for contour
       # usr <- par("usr"); on.exit(par(usr))
        #par(usr = c(range(x2[, -1]), range(x2[, -ncol(x2)]))) # set up limits
        points(Yx, Yy, col = zred, pch = 19, cex = 0.8)
        #contour(Yx, Yy, cntr, add=TRUE)
        #if(par('mfg')[2] == ncol(x2)) axis(4) # if right plot, add right axis
        #if(par('mfg')[1] == 1) axis(3) # if top plot, add top axis
      }, 
      #tick=FALSE, # suppress the default tick marks
      #line=1,
      gap = 0,
      xlim = c(0,1), ylim = c(0,1),
      labels = 1:d,
      oma = c(2, 18, 2, 2)) # move the default tick labels off the plot 

reset()

legend('left', legend = paste(1:d, colnames(lhs)), cex = 1.1, bty = 'n')
legend('topleft', pch = 19, col = c( zred, zblue), legend = c('failed', 'zero carbon cycle'), bty = 'n', inset = 0.02, cex = 1.1 )

#dev.off()

```


```{r, fig.width = 12, fig.height = 8}

#pdf(file = 'figs/run-failure-hists.pdf', width = 12, height = 8)

par(mfrow = c(4,8), mar = c(5,3,2,1))

for(i in 1:d){
  
  hist(x1[,i], xlim = c(0,1), breaks = seq(from=0, to = 1, by = 0.1), col = zblue, main = '', ylim = c(0,50),
       border = 'white', xlab = colnames(X_nlevel0)[i], ylab = '', las = 1, cex.lab = 1.5)
}

   
#dev.off()

```


```{r, fig.width = 12, fig.height = 8}

#pdf(file = 'figs/run-failure-hists.pdf', width = 12, height = 8)

par(mfrow = c(4,8), mar = c(5,3,2,1))

for(i in 1:d){
  
hist(x2[,i], xlim = c(0,1),breaks = seq(from=0, to = 1, by = 0.1), col = zred, border = 'white',
      main = '', xlab = colnames(X_nlevel0)[i], ylab = '', las = 1, cex.lab = 1.5)
  
}


```


## Re-examine bwl_io
A closer look at bwl_io now that the impact of f0_io has been removed shows a large number of "zero" NPP when bwl_io is at low values, which could well be the source of apparent sensitivity.

Take only higher values of bwl_io for the next round of constraints.

```{r, fig.width = 12, fig.height = 12}

p <- ncol(X_level1)

y_level1 <- Y_level1[,'npp_nlim_lnd_sum']

par(mfrow = c(5,7), mar = c(3,1,3,1))
for(i in 1:p){
  plot(X_level1[,i], y_level1, xlab = '', ylab = '', main = colnames(X_level1)[i])
}

```



```{r}

# Write an emulator wrapper

# Write a leave-one-out wrapper

# Create a list of emulator fits, for both km and twoStep methods.
# Use mclapply to build the lists
# use code from HDE package
# Make sure errors are handled adequately.


# Can we write it to use any emulator? (i.e km, twostep, something from another package?)
```


# History matching and generation of new ensemble members
To use History Matching, we need to specify targets for various model outputs. We treat these targets as "observations" with an uncertainty where a model run marked as "implausible" (beyond 3sd) matches the hard boundaries previously identified by A. Wiltshire as being desirable.

Choose the centre of the (implied) uniform distribution.
 cs_gb.target = (3000 - 750) / 2 =  1125
 cv.target = (800 - 300) / 2 = 250
 npp_n_gb.target = (80 - 35) / 2 = 22.5

 nbp.target = 0
 (gpp.target = 75)
 (runoff.target = 1)
 
(to do: visualise implausibility of design and loo emulated values of design as histogram) 

```{r}

# nbp  npp  csoil  cveg
Y_lower <- c(-10, 35, 750, 300)
Y_upper <- c(10, 80, 3000, 800)

# I'm going to set it so that + 4sd aligns approximately with the original limits
# given by Andy Wiltshire. This gives room for uncertainty from the emulator
Y_target = Y_upper - (abs(Y_upper - (Y_lower)) / 2 )# abs() to fix the problem with negative numbers


# standard deviation is derived from the limits and the central target
# (this distance is assumed to be 4 standard deviations.
Y_sd = (Y_upper - Y_target) / 4
names(Y_sd) = colnames(Y_const_level1a_scaled)


p = ncol(Y_const_level1a_scaled)

obs_sd_list = as.list(rep(0.01,p))
disc_list =  as.list(rep(0,p)) 
disc_sd_list =  as.list(Y_sd)
thres = 3

mins_aug = apply(X_level1a, 2, FUN = min)
maxes_aug =apply(X_level1a, 2, FUN = max)

# convert Y_target for ingestion into function
Y_target = matrix(Y_target, nrow = 1)

```


## visualise the constraints
```{r}

# Histogram of level 1 constraints
hcol = 'darkgrey'
lcol = 'black'

#pdf(file = 'figs/level_2_constraints_hists.pdf', width = 6, height = 5)
par(mfrow = c(2,2), fg = 'darkgrey', las = 1)


hist(Y_const_level1a_scaled[,'nbp_lnd_sum'], col = hcol, main = 'NBP', xlab = 'GtC/year')
polygon(x = c(0, 100, 100, 0), y = c(0, 0, 1000, 1000),
        col = makeTransparent('tomato2'),
        border = makeTransparent('tomato2'))

hist(Y_const_level1a_scaled[,'npp_nlim_lnd_sum'], col = hcol , main = 'NPP', xlab = 'GtC/year')
polygon(x = c(35, 80, 80, 35), y = c(0, 0, 1000, 1000),
        col = makeTransparent('tomato2'),
        border = makeTransparent('tomato2'))


        hist(Y_const_level1a_scaled[,'cSoil_lnd_sum'], col = hcol, main = 'Soil Carbon', xlab = 'GtC')
polygon(x = c(750, 3000, 3000, 750), y = c(0, 0, 1000, 1000),
        col = makeTransparent('tomato2'),
        border = makeTransparent('tomato2'))

hist(Y_const_level1a_scaled[,'cVeg_lnd_sum'], col = hcol, main = 'Vegetation Carbon', xlab = 'GtC')
polygon(x = c(300, 800, 800, 300), y = c(0, 0, 1000, 1000),
        col = makeTransparent('tomato2'),
       border =  makeTransparent('tomato2'))

#dev.off()

```



## Timeseries that match the constraints.
Plot the original ensemble, plus the stuff that matches the constraints. Include anomalies.
"Level 2" constraints are broad constraints produced by AW
```{r, fig.width = 12, fig.height = 9}

# remove to level 1a Relative to toplevel_ix - useful for plotting etc.
toplevel_to_level_1a_ix <-(toplevel_ix[-Y_nlevel0_ix])[level1a_ix]

# So further constraining to level 2 can be associated back to the top level.

level2_ix <- which(Y_const_level1a_scaled[,'nbp_lnd_sum'] > 0 &
                    Y_const_level1a_scaled[,'npp_nlim_lnd_sum'] > 35 &  Y_const_level1a_scaled[,'npp_nlim_lnd_sum'] < 80 &
                    Y_const_level1a_scaled[,'cSoil_lnd_sum'] > 750 & Y_const_level1a_scaled[,'cSoil_lnd_sum'] < 3000 &
                  Y_const_level1a_scaled[,'cVeg_lnd_sum'] > 300 & Y_const_level1a_scaled[,'cVeg_lnd_sum'] < 800
                  
                  
  )
```


## Pairs plots of level 2 input space
These are inputs that match the level 2 constraints. Only 37 of the original 500 members match these constraints. It's noticable how wide a region of parameter space these still come from.

```{r, fig.width = 10, fig.height = 10}
# Pairs plot of inputs that match the NBP constraint.


#pdf(file = 'figs/pairs_level2_inputs.pdf', width = 10, height = 10)
pairs(X_level1a[level2_ix,],
      xlim = c(0,1), ylim = c(0,1),
      labels = 1:d,
      col = makeTransparent('red', 150),
      gap = 0,
      pch = 20,
      xaxt ='n', yaxt = 'n',
      lower.panel = NULL,
      oma = c(0.5, 0.5, 0.5, 0.5)
)


reset()

legend('left', legend = paste(1:d, colnames(lhs)), cex = 0.9, bty = 'n', inset = 0.05, 0.05)

#dev.off()


```

We find that adding a constraint to level 2 constrains the behaviour of the soil carbon pool, but not the vegetation carbon pool. Probably not a surprise, given the Soil Carbon pool (and changes) are much larger than the vegetation carbon pool.

```{r vegC-soilC-constrained, fig.width = 12, fig.height = 8}
#cSoil_ens_anom [toplevel_to_level_1a_ix, ]

#pdf(file = 'figs/vegC-soilC-constrained.pdf', width = 12, height = 8)

par(mfrow= c(1,4), las = 1)

plotcol <- c(makeTransparent('black', 70))
overplotcol <- c(makeTransparent('tomato3', 200))


ylim = range(cSoil_ens)
matplot(years, t(cSoil_ens), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'GtC', main = 'cSoil',
        bty = 'n')
matlines( years, t((cSoil_ens[toplevel_to_level_1a_ix, ])[level2_ix, ]),col = overplotcol,  lwd = 1.5, lty = 'solid')

ylim = range(cSoil_ens)
matplot(years, t(cVeg_ens), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'GtC', main = 'cVeg',
        bty = 'n')
matlines( years, t((cVeg_ens[toplevel_to_level_1a_ix, ])[level2_ix, ]), col = overplotcol, lwd = 1.5, lty = 'solid')



ylim = range(cSoil_ens_anom)
matplot(years, t(cSoil_ens_anom), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'GtC', main = 'cSoil Anomaly',
        bty = 'n')
matlines( years, t((cSoil_ens_anom[toplevel_to_level_1a_ix, ])[level2_ix, ]),col = overplotcol, lwd = 1.5, lty = 'solid')


ylim = range(cVeg_ens_anom)
matplot(years, t(cVeg_ens_anom), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'GtC', main = 'cVeg Anomaly',
        bty = 'n')
matlines( years, t((cVeg_ens_anom[toplevel_to_level_1a_ix, ])[level2_ix, ]),col = overplotcol,lwd = 1.5, lty = 'solid')

#dev.off()

```


## Emulated density pairs plot of input space that matches level 2 constraints

```{r, include = FALSE}
# First build an emulator list for the Y

list_Y_const_level1a_scaled <- mat2list(Y_const_level1a_scaled)
emlist_Y_const_level1a_scaled <- mclapply(X = list_Y_const_level1a_scaled, FUN = km, formula = ~., design = X_level1a, mc.cores = 4) 

```


```{r}

# Samples from a uniform distribution across all of input space
nsamp_unif <- 100000   
X_unif <- samp_unif(nsamp_unif, mins = (rep(0, d)), maxes = rep(1,d))

Y_unif <- matrix(nrow = nsamp_unif, ncol = p)
colnames(Y_unif) <- colnames(Y_const_level1a_scaled)

# Build an emulator for each output individually
for(i in 1:p){
  #em <- km(~., design = X_level1a, response = Y_const_level1a_scaled[,i])
  #level1a_emlist[[i]] <- em
  em <- emlist_Y_const_level1a_scaled[[i]]
  pred <- predict(em, newdata = X_unif, type = 'UK')
  Y_unif[,i] <- pred$mean
}

# Find the inputs where the mean of the emulated output is 
# within the tolerable limits set by the modeller.
y_unif_ix_kept <- which(Y_unif[,'nbp_lnd_sum'] > 0 &
                    Y_unif[,'npp_nlim_lnd_sum'] > 35 & Y_unif[,'npp_nlim_lnd_sum'] < 80 &
                    Y_unif[,'cSoil_lnd_sum'] > 750 & Y_unif[,'cSoil_lnd_sum'] < 3000 &
                  Y_unif[,'cVeg_lnd_sum'] > 300 & Y_unif[,'cVeg_lnd_sum'] < 800
                  )
  
X_kept <- X_unif[y_unif_ix_kept, ]

# we've removed 80% of our prior input space
(nrow(X_kept) / nsamp_unif) * 100



```


```{r}
y_unif_ix_rejected = setdiff(1:nsamp_unif, y_unif_ix_kept)
X_rejected = X_unif[y_unif_ix_kept, ]
```

```{r,  fig.width = 10, fig.height = 10}
pdf(file = 'figs/pairs_dens_level2_km.pdf', width = 10, height = 10)
#dev.new(width = 10, height = 10)
par(oma = c(0,0,0,3), bg = 'white')
pairs(X_kept,
      labels = 1:d,
      gap = 0, lower.panel = NULL, xlim = c(0,1), ylim = c(0,1),
      panel = dfunc_up,
      cex.labels = 1,
      col.axis = 'white',
      dfunc.col = rb)

image.plot(legend.only = TRUE,
           zlim = c(0,1),
           col = rb,
           legend.args = list(text = 'Density of model runs matching the criteria', side = 3, line = 1),
           horizontal = TRUE
)

reset()

legend('left', legend = paste(1:d, colnames(lhs)), cex = 0.9, bty = 'n', inset = 0.05, 0.05)

dev.off()
```



## Constrain with Cumulative NBP
Email from ER:

Hello,

I’ve had a look for some multi-model ranges…

  From the ILAMB CMIP6 pages.
  NBP accumulated between 1959 and 2014: (227 INM)  -16.3 Gt to +106 Gt
GPP 1980-2014 mean: 104-144 Gt/yr (157 INM, 159 BCC)
cVeg 1996-2006 mean: 338-582 Gt (635 INM)
cSoil 2000-2001 mean: 319-1760 Gt

From Spencer’s recent paper about a subset of CMIP6 models.
NBP 2000-2009 mean: 0.45-2.24 Gt/yr

From Trendy 2019 ensemble, all are 1985-2014 means.
NBP: 0.21-1.82 Gt/yr
GPP: 107-165 Gt/yr
cVeg: 335-869 Gt
cSoil: 626-3595 Gt

I can update the Trendy results to the latest 2020 version and/or change the meaning period if needed.

Cheers,
Eddy.

```{r, width = 7, height = 7}
# Apply some constraints to NBP to see how much further it gets you
#From the ILAMB CMIP6 pages.
#NBP accumulated between 1959 and 2014: (-227 INM) -106 to +16.3 Gt


cumulative_nbp <- matrix(nrow = nrow(nbp_ens), ncol = ncol(nbp_ens))

for(i in 1:nrow(cumulative_nbp)){
  
  cnbp <- cumsum(nbp_ens[i, ])
  cumulative_nbp[i, ] <- cnbp
  
}

par(mfrow = c(1,2))
matplot(t(nbp_ens), main = 'NBP', type = 'l', ylab = 'GtC/year', col = plotcol, ylim = c(-10, 10))

ylim = c(-150, 200)

matplot(years, t(cumulative_nbp), type = 'l', lty = 'solid',ylim = ylim, col = plotcol, 
        ylab = 'GtC', main = 'cumulative NBP', xlab = '',
        bty = 'n')

```

If we constrain on cumulative NBP that matched ILAMB 1959 - 2013 (the latest year in the record, we choose those ensemble members which have the lowest cumulative NBP. Many ensemble members have a higher cumulative NBP.)
```{r, fig.width = 5, fig.height = 7}
# extract nbp accumulated between 1959 and 2014:

nbpcol <- c(makeTransparent('tomato3', 150))
awcol <- c(makeTransparent('blue', 150))

start_ix = which(years == 1959)
end_ix <- which(years == 2013)


nbp_modern_accum <- cumulative_nbp[, end_ix] - cumulative_nbp[, start_ix]


#par(mfrow = c(2,1))
#hist(nbp_modern_accum , xlim = c(-100, 150))

nbp_modern_accum_level1a <- nbp_modern_accum[toplevel_to_level_1a_ix]

#hist(nbp_modern_accum_level1a , xlim = c(-100, 150))

nbp_accum_ix <- which(nbp_modern_accum_level1a > -16.3 &  nbp_modern_accum_level1a < 106)

ylim = range(c(-120, 200))

#pdf(file = 'figs/cumulative_nbp_constrained.pdf', width = 5, height = 7)
matplot(years, t(cumulative_nbp), type = 'l', lty = 'solid',ylim = ylim, col = plotcol,
        ylab = 'GtC', main = 'cumulative NBP',
        bty = 'n', lwd = 1.5)
matlines( years, t((cumulative_nbp[toplevel_to_level_1a_ix, ])[nbp_accum_ix, ]),col = nbpcol,lwd = 2, lty = 'solid')
matlines( years, t((cumulative_nbp[toplevel_to_level_1a_ix, ])[level2_ix, ]),col = awcol,lwd = 2, lty = 'solid')

legend('topleft', legend  = c('Cumulative NBP constraint', 'AW constraint'), col = c(nbpcol, awcol) , lty = 'solid', lwd = 2)
#dev.off()


```

## How do we find outputs that are inconsistent?
It's clear that something rules out all the "good" values of cumulative_nbp. Which output is it?   

1) There is a very strong relationship (almost 1:1) between nbp_lnd_sum and cumulative_nbp. The cumulative NBP constraint keeps the 'modern' nbp low, while Andy's constraints do not.

2) All the cumulative NBP-constrained ensemble members have low modern vegetation carbon

3) Modern NPP and soil carbon
#

```{r, fig.width = 9,  fig.height = 9}

Y_const_level1a_scaled_nbp <- cbind(Y_const_level1a_scaled, nbp_modern_accum_level1a)

colnames(Y_const_level1a_scaled_nbp) <- c(colnames(Y_const_level1a_scaled), 'cumulative_nbp')

outcols <- rep(makeTransparent('black', 50), nrow(Y_const_level1a_scaled_nbp))

outcols[nbp_accum_ix ] <- nbpcol
outcols[level2_ix] <- awcol

#pdf(file = 'figs/cumulative_nbp_constrained_pairs.pdf', width = 9, height = 9)

pairs(Y_const_level1a_scaled_nbp, col = outcols, lower.panel = NULL, pch = 19)
reset()
legend('bottomleft', legend  = c('Cumulative NBP constraint', 'AW constraint'), col = c(nbpcol, awcol) , pch = 19, cex = 1.5,
       inset = 0.1)
#  dev.off()

```


## Augment the design.
The function addNroyDesignPoints builds an emulator for each model output in Y. It compares the output of each emulator at a number of candidate desin points, and chooses a space-filling set of them that that are Not Ruled Out Yet (statistically close to the observation at Y_target).

```{r, warning=FALSE, message=FALSE, results='hide'}
# Final output needs to be expressed in terms of original LHS, then put back out to conf files.

# This function adds n.aug potential design points, and finds their implausibility
# score in X.nroy

wave1 = addNroyDesignPoints(X = X_level1a, 
                            Y = Y_const_level1a_scaled, 
                            Y_target = Y_target,
                            n_aug = 50000, 
                            mins_aug = mins_aug,
                            maxes_aug = maxes_aug,
                            thres = 3,
                            disc_list=disc_list,
                            disc_sd_list = disc_sd_list,
                            obs_sd_list = obs_sd_list,
                            n_app = 500,
                            nreps = 500,
                            mc.cores = 4)
```




## Write the augmented design
The function write_jules_design here simply takes the points calculated by addNroyDesignPoints and writes them to configuration files.

```{r}

# this needs sorting
source('~/myRpackages/julesR/vignettes/default_jules_parameter_perturbations.R')

# Easiest way to generate a design of the right size is to have a "fac" which takes
# the names from the parameter list, and then multiplies everything by 0.5 or 2

tf <- 'l_vg_soil'
# we don't want anything that is TRUE/FALSE to be in fac
fac_init <- names(paramlist)
not_tf_ix <- which(names(paramlist)!=tf)
paramlist_trunc <-paramlist[not_tf_ix]

fac <- names(paramlist_trunc)

maxfac <-lapply(paramlist_trunc,function(x) x$max[which.max(x$max)] / x$standard[which.max(x$max)])
minfac <- lapply(paramlist_trunc,function(x) x$min[which.max(x$max)] / x$standard[which.max(x$max)])


```


```{r}
# create a directory for the configuration files
confdir <- 'conf_files_augment_JULES-ES-1p0'

dir.create(confdir)

X_mm <- wave1$X_mm

# This is the function that writes the configuration files.
write_jules_design(X_mm = X_mm, paramlist=paramlist, n = nrow(X_mm),
                    fac = fac, minfac = minfac, maxfac = maxfac,
                    tf = tf,
                    fnprefix = paste0(confdir,'/param-perturb-P'),
                    lhsfn = paste0(confdir,'/lhs_example.txt'),
                    stanfn = paste0(confdir,'/stanparms_example.txt'),
                    allstanfn = paste0(confdir,'/allstanparms_example.txt'),
                    rn = 12,
                    startnum = 499)
```

## Check the design
Check that the augmented design produces what we expect. New ensemble members should be somewhat constrained within the boundaries of the original design, if the comparison to data offers any constraint.

```{r, fig.width = 12, fig.height = 12}


X_mm <- wave1$X_mm

# pairs(rbind(X, X_mm), xlim = c(0,1), ylim = c(0,1), gap = 0, lower.panel = NULL, 
#       col = c(rep('grey', nrow(X)), rep('red', nrow(X_mm))),
#       pch = c(rep(21, nrow(X)), rep(20, nrow(X_mm)))
#       )
# 
# par(xpd = NA)
# 
# legend('bottom',
#        legend = c('Original design', 'New points'),
#        col = c('grey', 'red'),
#        inset = 0.15,
#        cex = 1.5,
#        pch = c(21,20)
# )

par(oma = c(0,0,0,3), bg = 'white')
pairs(X_mm,
      labels = 1:d,
      gap = 0, lower.panel = NULL, xlim = c(0,1), ylim = c(0,1),
      panel = dfunc_up,
      cex.labels = 1,
      col.axis = 'white',
      dfunc.col = rb)

image.plot(legend.only = TRUE,
           zlim = c(0,1),
           col = rb,
           legend.args = list(text = 'Density of model runs matching the criteria', side = 3, line = 1),
           horizontal = TRUE
)

```


Visualise the predicted outputs at the NROY points of the old design, and the new suggested design.
```{r}
Y_mm_list <- vector(mode ='list', length = length(wave1$fit_list))

for(i in 1:length(wave1$fit_list)){

y_mm <- predict(object=wave1$fit_list[[i]], newdata = wave1$X_mm, type = 'UK')

Y_mm_list[[i]] <- y_mm

}
```

## Visualising the emulated outputs at the proposed new design points.

Interestingly, these aren't perfectly within the original hard boundaries set by Andy, even though I've set those boundaries to be the +- 4 standard deviation threholds in the History Match. I suggest this is because there is model discrepancy, and that there is considerable wriggle room induced from emulator uncertainty.

In particular, it appears that vegetation carbon is difficult to keep high, and that many NROY proposed members have a fairly low vegetation carbon. This might need a discrepancy term, or adjusting in some other way. It certainly needs exploring, and a OAAT plot might give clues as to the parameters to choose.

```{r, fig.width = 8, fig.height = 8}
# Histogram of level 1 constraints

pdf(file = 'figs/emulated_design_points.pdf', width = 8, height = 8)
hcol = 'darkgrey'
lcol = 'black'
par(mfrow = c(2,2), fg = 'darkgrey', las = 1, oma = c(1,1,4,1))

discsd <- c(disc_sd_list, recursive = TRUE)

hist(Y_const_level1a_scaled[,'nbp_lnd_sum'], col = hcol, main = 'NBP', xlab = 'GtC/year')
hist(Y_mm_list[[1]]$mean, add = TRUE, col = 'black')
polygon(x = c(-10, 100, 100, -10), y = c(0, 0, 1000, 1000),
        col = makeTransparent('tomato2'),
        border = makeTransparent('tomato2'))
rug(Y_target[1], col = 'black')
rug(c(Y_target[1] + 3*discsd[1],Y_target[1] - 3*discsd[1]) , col = 'red')

hist(Y_const_level1a_scaled[,'npp_nlim_lnd_sum'], col = hcol , main = 'NPP', xlab = 'GtC/year')
hist(Y_mm_list[[2]]$mean, add = TRUE, col = 'black')
polygon(x = c(35, 80, 80, 35), y = c(0, 0, 1000, 1000),
        col = makeTransparent('tomato2'),
        border = makeTransparent('tomato2'))
rug(Y_target[2], col = 'black')
rug(c(Y_target[2] + 3*discsd[2],Y_target[2] - 3*discsd[2]) , col = 'red')

hist(Y_const_level1a_scaled[,'cSoil_lnd_sum'], col = hcol, main = 'Soil Carbon', xlab = 'GtC')
hist(Y_mm_list[[3]]$mean, add = TRUE, col = 'black')
polygon(x = c(750, 3000, 3000, 750), y = c(0, 0, 1000, 1000),
        col = makeTransparent('tomato2'),
        border = makeTransparent('tomato2'))
rug(Y_target[3], col = 'black')
rug(c(Y_target[3] + 3*discsd[3],Y_target[3] - 3*discsd[3]) , col = 'red')

hist(Y_const_level1a_scaled[,'cVeg_lnd_sum'], col = hcol, main = 'Vegetation Carbon', xlab = 'GtC')
hist(Y_mm_list[[4]]$mean, add = TRUE, col = 'black')
polygon(x = c(300, 800, 800, 300), y = c(0, 0, 1000, 1000),
        col = makeTransparent('tomato2'),
       border =  makeTransparent('tomato2'))
rug(Y_target[4], col = 'black')
rug(c(Y_target[4] + 3*discsd[4],Y_target[4] - 3*discsd[4]) , col = 'red')

reset()

legend('top', horiz = TRUE, fill = c(hcol, makeTransparent('tomato2'), 'black'), legend = c('runs', 'constraint', 'emulated design outputs'), text.col = 'black', cex = 1, bty = 'n')

dev.off()

  
```



```{r, fig.width = 10, fig.height = 10}
# Pairs plot of inputs that match the NBP constraint.


pairs(X_level1a[nbp_accum_ix,],
      xlim = c(0,1), ylim = c(0,1),
      labels = 1:d,
      col = makeTransparent('red', 150),
      gap = 0,
      pch = 20,
      xaxt ='n', yaxt = 'n',
      lower.panel = NULL,
      oma = c(0.5, 0.5, 0.5, 0.5)
)

```


```{r}
# Does NBP rule out members which are not ruled out by Andy? 





```




```{r }

# 1837 < cSoil < 3257 Pg
# 380 < cVeg < 536 Pg
# 100 < gpp < 150 Pg/yr
# 133 < nSoil < 152 Pg
# Plus decadal ranges of NBP (1960-2019) from -0.4 Pg/yr to +2.6 Pg/yr, where NBP is the net flux into the land including land-use
# emissions.

level3_ix <- which(Y_const_level1a_scaled[,'nbp_lnd_sum'] > -0.4 & Y_const_level1a_scaled[,'nbp_lnd_sum'] < 2.6 &
                    Y_const_level1a_scaled[,'cSoil_lnd_sum'] > 1837 & Y_const_level1a_scaled[,'cSoil_lnd_sum'] < 3257 &
                  Y_const_level1a_scaled[,'cVeg_lnd_sum'] > 380 & Y_const_level1a_scaled[,'cVeg_lnd_sum'] < 536
  )
  

```




## Atmospheric growth
We can calculate the atmospheric growth as Fossil fule emissions (GCB) - Ocean uptake  (GCB) - net land flux (JULES NBP)

Conversely, we can calculate the land uptake as NBP = FF - ocean - ag (Do we have AG in JULES?)

```{r}

resid <- historical_carbon_budget$`ocean sink` - historical_carbon_budget$`fossil emissions excluding carbonation`

resid_ix <- which(historical_carbon_budget$Year %in% years)

neg_ag <- sweep(nbp_ens, 2, resid[resid_ix], FUN = '+')


matplot(years, t(-neg_ag), type = 'l', lty = 'solid',ylim = c(0, 8), col = plotcol, 
         ylab = 'GtC', main = 'atmospheric growth', xlab = '',
         bty = 'n', xlim = c(1960, 2020))

lines(historical_carbon_budget$Year, historical_carbon_budget$`atmospheric growth`, col = 'red')


```


### another way to calclulate atmospheric growth

These two methods give very similar outcomes, bar an outlier.

```{r, fig.width = 8, fig.height = 7}

ag <- matrix(nrow = nrow(nbp_ens), ncol = ncol(nbp_ens))
for(i in 1:nrow(nbp_ens)){
  
  ag[i, ] <- historical_carbon_budget$`fossil emissions excluding carbonation`[resid_ix] - historical_carbon_budget$`ocean sink`[resid_ix] -  nbp_ens[i, ]
  
}

#pdf(width = 8, height = 6, file = 'ag.pdf')
matplot(years, t(ag), type = 'l', lty = 'solid',ylim = c(0, 8), col = 'darkred', 
         ylab = 'GtC', main = 'atmospheric growth', xlab = '',
         bty = 'n', xlim = c(1960, 2020))

lines(historical_carbon_budget$Year, historical_carbon_budget$`atmospheric growth`, col = 'black', lwd =2)
#dev.off()

```





### Land carbon Sink?

I think to make a fair comparison, we might need to take the diff of the anomaly (or just the timeseries), as the above represents the total change since 1850, and I think all the "land sink" stuff looks at the year-to-year changes.

```{r total-land-carbon-sink, warning = FALSE, message = FALSE}

landsink_ens <- matrix(NA, nrow = nrow(total_land_carbon_ens), ncol = ncol(total_land_carbon_ens)-1)

for(i in 1:nrow(landsink_ens)){
  
  landsink_ens[i, ] <- diff(total_land_carbon_ens[i, ])
}


ylim = range(landsink_ens)
matplot(years[-1], t(landsink_ens), type = 'l', lty = 'solid',ylim = ylim, col = plotcol, xlab = '',
        ylab = 'GtC/year', main = 'Total land carbon sink',
        bty = 'n')
matlines( years[-1], t((landsink_ens[toplevel_to_level_1a_ix, ])[level2_ix, ]), col = 'tomato3', lty = 'solid')

lines(historical_carbon_budget$Year, historical_carbon_budget$`land sink`, col = 'blue', lwd = 2, xlab = '')
legend('bottomleft', legend = c('Ruled out','level 1a constrained','historical'), col = c('black','tomato3', 'blue' ), lty ='solid',
       lwd = c(1,1,2))


```


### Identify parts of parameter space where the land carbon sink is at its maximum
What do these parts of parameter space tell us about what we need to do to have the model reproduce reality?
```{r}

# Build an emulator for total land carbon uptake at the end of the century


# ensemble of modern landsink
landsink_modern_ix <- which(years[-1] %in% 1994:2013)

landsink_modern_ens <- (apply(landsink_ens[, landsink_modern_ix], 1, mean))

landsink_modern_ens_level1a <- landsink_modern_ens[toplevel_to_level_1a_ix]

# observations of modern land sink

hist_ix <- which(historical_carbon_budget$Year %in% 1994:2013)
landsink_modern_obs <- mean(historical_carbon_budget$`land sink`[hist_ix ])

# This is all 499 members
landsink_modern_err <- landsink_modern_ens - landsink_modern_obs

landsink_modern_err_level1a <- landsink_modern_err[toplevel_to_level_1a_ix]#



#[level2_ix, ]

# Build emulators 

# Identify the parts of parameter space where the differences are low


# Are we getting close for the right reasons? What else is going wrong?




```


```{r, fig.width = 12, fig.height = 6}


par(mfrow = c(4,8), mar = c(3,2,2,1))
for(i in 1:d){
  
  plot(X_level1a[, i],landsink_modern_err_level1a, )
  
}


```

```{r, results = 'hide'}
  

fit_landsink_err <- km(~.,design = X_level1a, response =  landsink_modern_err_level1a)


```
```{r, fig.width = 6, fig.height = 8}

plot(fit_landsink_err)

```

### what parts of parameter space are the closest?
```{r}

# Two strategies - plot land sink error against parameters, and identify bits of parameter space with smallest error

#low_error_ix <- landsink_modern_err_level1a


mins <- apply(X_level1a,2,FUN = min)
maxes <- apply(X_level1a,2,FUN = max)
  
nsamp_unif <- 100000  
X_unif <- samp_unif(nsamp_unif, mins = mins, maxes = maxes)

pred_unif <- predict(fit_landsink_err, newdata = X_unif, type = 'UK')

```

```{r, fig.width = 12, fig.height = 12, warning=FALSE, message = FALSE}


par(oma = c(0,0,0,3), bg = 'white')
pairs(X_level1a,
      labels = 1:d,
      gap = 0, lower.panel = NULL, xlim = c(0,1), ylim = c(0,1),
      panel = cpoints,
      z= landsink_modern_ens_level1a,
      col = byr,
      cex.labels = 1,
      col.axis = 'white',
      pch = 20
      )

#image.plot(legend.only = TRUE,
#           zlim = c(0,1),
#           col = blues,
#           legend.args = list(text = 'Density of model runs matching the criteria', side = 3, line = 1),
#           horizontal = TRUE
#)

#  legend('left', legend = paste(1:d, colnames(lhs)), cex = 0.9, bty = 'n')


```

```{r, message = FALSE, warning = FALSE, fig.width = 12, fig.height = 12}


X_kept <- X_unif[abs(pred_unif$mean) < 1, ] 

par(oma = c(0,0,0,3), bg = 'white')
pairs(X_kept,
      labels = 1:d,
      gap = 0, lower.panel = NULL, xlim = c(0,1), ylim = c(0,1),
      panel = dfunc_up,
      cex.labels = 1,
      col.axis = 'white',
      dfunc.col = blues)

image.plot(legend.only = TRUE,
           zlim = c(0,1),
           col = blues,
           legend.args = list(text = 'Density of model runs matching the criteria', side = 3, line = 1),
           horizontal = TRUE
)

legend('left', legend = paste(1:d, colnames(lhs)), cex = 0.9, bty = 'n')





```

```{r, fig.width = 12, fig.height = 6}

par(mfrow = c(4,8), mar = c(3,2,2,1))

for(i in 1:d){
  
  hist(X_kept[, i], col = 'grey', border = 'white', 
        xlim = c(0,1), breaks = seq(from = 0, to = 1, by = 0.1),
       main = colnames(X_kept)[i])
  
}


```





How good are the four emulators that we've built? Are there biases? (there's no real evidence of this)
```{r, fig.width = 8, fig.height = 8}

par(mfrow = c(2,2))

for(i in 1:4){
  
hist(wave1$pred_list[[i]]$mean, main = colnames(Y_const_level1a_scaled)[i])
  
}


```



What do the emulators make of the design points which actually make Andy's "hard boundary" criteria?
If we leave them out, do they still place the output within the hard boundaries?

```{r}

  aw_boundary_ix = which(Y_const_level1a_scaled[,'nbp_lnd_sum'] > -10 &
                      Y_const_level1a_scaled[,'npp_nlim_lnd_sum'] > 35 &  Y_const_level1a_scaled[,'npp_nlim_lnd_sum'] < 80 &
                      Y_const_level1a_scaled[,'cSoil_lnd_sum'] > 750 & Y_const_level1a_scaled[,'cSoil_lnd_sum'] < 3000 &
                    Y_const_level1a_scaled[,'cVeg_lnd_sum'] > 300 & Y_const_level1a_scaled[,'cVeg_lnd_sum'] < 800
    )



X_aw_boundary = X_level1a[aw_boundary_ix, ]
Y_aw_boundary = Y_const_level1a_scaled[aw_boundary_ix, ]

```

## Check the emulators that produce the new design
Do a leave-one-out cross validation of points inside the hard boundaries using the wave1 fits.
```{r}
# quickest to find the loo predictions at the right indices


```

```{r}

loo_mean_Y_level1a <- matrix(nrow = nrow(X_level1a), ncol = ncol(Y_const_level1a_scaled))
loo_sd_Y_level1a <- matrix(nrow = nrow(X_level1a), ncol = ncol(Y_const_level1a_scaled))
  
  for(i in 1:ncol(Y_const_level1a_scaled)){

loo <- leaveOneOut.km(wave1$fit_list[[i]],type = 'UK', trend.reestim = TRUE )
  loo_mean_Y_level1a[,i] <- loo$mean
  loo_sd_Y_level1a[,i] <- loo$sd
}

```

We see in the leave-one-out analysis that the emulator is consistently under-predicting the vegetation carbon (though the uncertainty estimate often covers the actual value).This suggests (1) that there isn't really a huge problem with a model discrepancy (or at least that isn't the only problem), and (2) the history matching is working as it should, and taking into account a not-great emulator.

```{r, fig.width = 8, fig.height = 8}

par(mfrow = c(2,2))

for(i in 1:ncol(loo_mean_Y_level1a)){
  
  rn <- range(c(loo_mean_Y_level1a[aw_boundary_ix,i] - (2*loo_sd_Y_level1a[aw_boundary_ix,i]) , loo_mean_Y_level1a[aw_boundary_ix,i] + (2*loo_sd_Y_level1a[aw_boundary_ix,i]) ))
  
  
  
  plot(Y_const_level1a_scaled[aw_boundary_ix, i], loo_mean_Y_level1a[aw_boundary_ix,i], ylim = rn, main = colnames(Y_const_level1a_scaled)[i], xlab = 'actual', ylab = 'predicted')
  
  segments(x0 = Y_const_level1a_scaled[aw_boundary_ix, i], y0 = loo_mean_Y_level1a[aw_boundary_ix,i] - (2*loo_sd_Y_level1a[aw_boundary_ix,i])  , x1 = Y_const_level1a_scaled[aw_boundary_ix, i] , y1 = loo_mean_Y_level1a[aw_boundary_ix,i] + (2*loo_sd_Y_level1a[aw_boundary_ix,i]) , col = makeTransparent('black', 70))
  abline(0,1)
  
}


```

## Compare the straight km with a two-step emulator
Is a two-step emulator any better at emulating those crucial points which fall within aw's hard boundaries? First, create a list of emulator fits.

```{r}

fitlist_Y_const_level1a_scaled <- vector(mode = 'list', length = ncol(Y_const_level1a_scaled))

for(i in 1:ncol(Y_const_level1a_scaled)){
  
  y <- Y_const_level1a_scaled[,i]
  fit <- twoStep_glmnet(X = X_level1a, y)
  fitlist_Y_const_level1a_scaled[[i]] <- fit

}


```

```{r}
loo_mean_glmnet_Y_level1a <- matrix(nrow = nrow(X_level1a), ncol = ncol(Y_const_level1a_scaled))
loo_sd_glmnet_Y_level1a <- matrix(nrow = nrow(X_level1a), ncol = ncol(Y_const_level1a_scaled))
  
  for(i in 1:ncol(Y_const_level1a_scaled)){

loo <- leaveOneOut.km(fitlist_Y_const_level1a_scaled[[i]]$emulator,type = 'UK', trend.reestim = TRUE )
  loo_mean_glmnet_Y_level1a[,i] <- loo$mean
  loo_sd_glmnet_Y_level1a[,i] <- loo$sd
}

```

It doesn't appear that the two-step emulator (here plotted in red) is doing any better than the regular emulator.
```{r, fig.width = 8, fig.height = 8}
par(mfrow = c(2,2))

for(i in 1:ncol(loo_mean_Y_level1a)){
  
  rn <- range(c(loo_mean_Y_level1a[aw_boundary_ix,i] - (2*loo_sd_Y_level1a[aw_boundary_ix,i]) , loo_mean_Y_level1a[aw_boundary_ix,i] + (2*loo_sd_Y_level1a[aw_boundary_ix,i]) ))
  
  
  
  plot(Y_const_level1a_scaled[aw_boundary_ix, i], loo_mean_Y_level1a[aw_boundary_ix,i], ylim = rn, main = colnames(Y_const_level1a_scaled)[i], xlab = 'actual', ylab = 'predicted')
  
  points(Y_const_level1a_scaled[aw_boundary_ix, i], loo_mean_glmnet_Y_level1a[aw_boundary_ix,i], col = 'red')
  
  
  segments(x0 = Y_const_level1a_scaled[aw_boundary_ix, i], y0 = loo_mean_Y_level1a[aw_boundary_ix,i] - (2*loo_sd_Y_level1a[aw_boundary_ix,i])  , x1 = Y_const_level1a_scaled[aw_boundary_ix, i] , y1 = loo_mean_Y_level1a[aw_boundary_ix,i] + (2*loo_sd_Y_level1a[aw_boundary_ix,i]) , col = makeTransparent('black', 70))
  abline(0,1)
  
}
```

Two other things I can think of to check: 1) how about using "multistart" to choose different starting conditions for optimising the emulators and 2) Using a flat prior for the mean function rather than a linear prior.
```{r}

fitlist_flatprior_Y_const_level1a_scaled <- vector(mode = 'list', length = ncol(Y_const_level1a_scaled))

for(i in 1:ncol(Y_const_level1a_scaled)){
  
  y <- Y_const_level1a_scaled[,i]
  fit <- km(formula =~1, design = X_level1a, response = y)
  fitlist_flatprior_Y_const_level1a_scaled[[i]] <- fit

}


```

```{r}
loo_mean_flatprior_Y_level1a <- matrix(nrow = nrow(X_level1a), ncol = ncol(Y_const_level1a_scaled))
loo_sd_flatprior_Y_level1a <- matrix(nrow = nrow(X_level1a), ncol = ncol(Y_const_level1a_scaled))
  
  for(i in 1:ncol(Y_const_level1a_scaled)){

loo <- leaveOneOut.km(fitlist_flatprior_Y_const_level1a_scaled[[i]],type = 'UK', trend.reestim = TRUE )
  loo_mean_flatprior_Y_level1a[,i] <- loo$mean
  loo_sd_flatprior_Y_level1a[,i] <- loo$sd
}

```

```{r, fig.width = 8, fig.height = 8}
par(mfrow = c(2,2))

for(i in 1:ncol(loo_mean_Y_level1a)){
  
  rn <- range(c(loo_mean_Y_level1a[aw_boundary_ix,i] - (2*loo_sd_Y_level1a[aw_boundary_ix,i]) , loo_mean_Y_level1a[aw_boundary_ix,i] + (2*loo_sd_Y_level1a[aw_boundary_ix,i]) ))
  
  
  
  plot(Y_const_level1a_scaled[aw_boundary_ix, i], loo_mean_Y_level1a[aw_boundary_ix,i], ylim = rn, main = colnames(Y_const_level1a_scaled)[i], xlab = 'actual', ylab = 'predicted')
  
  points(Y_const_level1a_scaled[aw_boundary_ix, i], loo_mean_flatprior_Y_level1a[aw_boundary_ix,i], col = 'red')
  
  
  segments(x0 = Y_const_level1a_scaled[aw_boundary_ix, i], y0 = loo_mean_Y_level1a[aw_boundary_ix,i] - (2*loo_sd_Y_level1a[aw_boundary_ix,i])  , x1 = Y_const_level1a_scaled[aw_boundary_ix, i] , y1 = loo_mean_flatprior_Y_level1a[aw_boundary_ix,i] + (2*loo_sd_flatprior_Y_level1a[aw_boundary_ix,i]) , col = makeTransparent('black', 70))
  abline(0,1)
  
}



```



# Exploring new constraints
Input from Eddy Robertson:

"We can assume that the majority of vegetation carbon is stored in tree trunks so, the carbon density of trees is approximately (cVeg_lnd_mean / treeFrac_lnd_mean). Although I suppose it's possible that in the PPE the shrubs have become tree-like, so it might be interesting to plot cVeg_lnd_mean versus  (shrubFrac_lnd_mean + treeFrac_lnd_mean) as well. The first question is whether cVeg_lnd_mean increases linearly with treeFrac_lnd_mean. Then if this turned out to be interesting, we could produce a treeCVeg_lnd_mean output."

```{r, fig.width = 7, fig.height = 7}

#pdf(file = 'vegC_density.pdf', width = 6, height = 6)
plot(Y_level0[,'treeFrac_lnd_mean'],Y_level0[,'cVeg_lnd_mean'], main = "Vegetation (tree) carbon density, Level0",
     xlab = 'treeFrac_lnd_mean', ylab  = 'cVeg_lnd_mean' )

#dev.off()

```

Is the range of carbon densities narrower in the "hard boundary" set?
```{r, fig.width = 6, fig.height = 6}

Y_level1a_aw <- Y_level1a[aw_boundary_ix, ]
X_level1a_aw <- X_level1a[aw_boundary_ix, ]

#pdf(file = 'vegC_density_aw.pdf', width = 6, height = 6)
plot(Y_level1a[,'treeFrac_lnd_mean'],Y_level1a[,'cVeg_lnd_mean'], main = "Vegetation (tree) carbon density",
     xlab = 'treeFrac_lnd_mean', ylab  = 'cVeg_lnd_mean' )

points( Y_level1a_aw[,'treeFrac_lnd_mean'],Y_level1a_aw[,'cVeg_lnd_mean'], pch = 19, col = 'red')
legend('topleft', legend = c('Level1a','AW constraints'), pch = c(21, 19), col = c('black', 'red'))
#   dev.off()



```




```{r}
c_density <- Y_level1a[,'treeFrac_lnd_mean'] / Y_level1a[,'cVeg_lnd_mean']

hist(c_density)



```

## Now that we have constraints, we can explore their effect on the output 

```{r, fig.width = 20, fig.height = 20}
# Pairs plot of output
y_names_mean <- c('nbp_lnd_mean', 'fLuc_lnd_mean', 'npp_nlim_lnd_mean', 'cSoil_lnd_mean',
            'cVeg_lnd_mean', 'landCoverFrac_lnd_mean', 'fHarvest_lnd_mean',
            'lai_lnd_mean', 'rh_lnd_mean', 'treeFrac_lnd_mean', 'c3PftFrac_lnd_mean', 
            'c4PftFrac_lnd_mean', 'shrubFrac_lnd_mean', 'baresoilFrac_lnd_mean')

Y_level1a_mean <- Y_level1a[,y_names_mean]

pcol <- rep('black', nrow(Y_level1a_mean))
pcol[aw_boundary_ix] <- 'red'
pairs(Y_level1a_mean, col = pcol, lower.panel = NULL, pch = 19, cex.labels = 1.5)




```

## How much does constraining an output constrain other outputs?
For example, what effect has the AW "hard boundary" constraint produced on ranges of the other (marginal) outputs? Which constraint is doing the majority of the work?


A function to find the proportion of output space that is removed (or retained) when applying a constraint.
```{r}

constraint_prop <- function(Y, constraint_ix){
  
  Yconst <- Y[constraint_ix, ]
  Yconst_norm <- normalize(Yconst, wrt = Y)
  rn <- apply(Yconst_norm, 2, range)
  out <- rn
  out
  
}


```

```{r}
Y_constraint_plot <- function(constraint_range, constraint_columns, ...){
  # A function to plot the output of constraint_prop
  
  par(mar = c(12,4,3,2),las = 2)

pcol = rep('black', ncol(constraint_range))
pcol[constraint_columns] <- 'red' # plot the outputs where we have specified the constraints in red.

plot(1:ncol(constraint_range),constraint_range[2,], ylim = c(0,1) , axes = FALSE, xlab = '', ylab = 'range of ensemble (fraction)', col = pcol, pch = 19, ...)
points(1:ncol(constraint_range), constraint_range[1,], col = pcol, pch = 19)
segments(x0 = 1:ncol(constraint_range), y0 = constraint_range[1,], x1 = 1:ncol(constraint_range), y1 = constraint_range[2,], col = pcol, lwd =2 )

axis(side = 1, labels = colnames(constraint_range), at = 1:ncol(constraint_range))
axis(2)
abline(h = c(0,1), col = 'red')
  
}
```

All constraints together take the normalized range of all the outputs to a little under a half of the original range, on average. Of course, four of the inputs are constrained here, which has quite a large impact.
```{r}
Y_level1a_mean_aw_norm_rn <- constraint_prop(Y = Y_level1a_mean, constraint_ix = aw_boundary_ix)
mean_constraint_all <- mean(Y_level1a_mean_aw_norm_rn[2, ] - Y_level1a_mean_aw_norm_rn[1, ])
Y_constraint_plot(Y_level1a_mean_aw_norm_rn,constraint_columns = c(c(1,3,4,5)), main = paste('mean constrained range =', round(mean_constraint_all,3)))
```

We can see what impacts the constraints have individually
```{r}

nbp_ix <- which(Y_const_level1a_scaled[,'nbp_lnd_sum'] > -10)
npp_ix <- which(Y_const_level1a_scaled[,'npp_nlim_lnd_sum'] > 35 &  Y_const_level1a_scaled[,'npp_nlim_lnd_sum'] < 80 )
cSoil_ix <- which(Y_const_level1a_scaled[,'cSoil_lnd_sum'] > 750 & Y_const_level1a_scaled[,'cSoil_lnd_sum'] < 3000)
cVeg_ix <- which(Y_const_level1a_scaled[,'cVeg_lnd_sum'] > 300 & Y_const_level1a_scaled[,'cVeg_lnd_sum'] < 800)

```

The NBP constraint has no marginal impact
```{r}

Y_level1a_mean_nbp_const <- constraint_prop(Y = Y_level1a_mean, constraint_ix = nbp_ix )
mean_constraint_nbp <- mean(Y_level1a_mean_nbp_const[2, ] - Y_level1a_mean_nbp_const[1, ])
Y_constraint_plot(Y_level1a_mean_nbp_const,1,  main = paste('mean constrained range =', round(mean_constraint_nbp,3)))

```

```{r}

Y_level1a_mean_npp_const <- constraint_prop(Y = Y_level1a_mean, constraint_ix = npp_ix )
mean_constraint_npp <- mean(Y_level1a_mean_npp_const[2, ] - Y_level1a_mean_npp_const[1, ])
Y_constraint_plot(Y_level1a_mean_npp_const,3,  main = paste('mean constrained range =', round(mean_constraint_npp,3)))

```


```{r}

Y_level1a_mean_cSoil_const <- constraint_prop(Y = Y_level1a_mean, constraint_ix = cSoil_ix )
mean_constraint_cSoil <- mean(Y_level1a_mean_cSoil_const[2, ] - Y_level1a_mean_cSoil_const[1, ])
Y_constraint_plot(Y_level1a_mean_cSoil_const,4,  main = paste('mean constrained range =', round(mean_constraint_cSoil,3)))

```
Vegetation carbon (cVeg) has the strongest impact on everything else. This is no suprise, given that so few of the ensemble members seem to simulate carbon vegetation high enough.
```{r}

Y_level1a_mean_cVeg_const <- constraint_prop(Y = Y_level1a_mean, constraint_ix = cVeg_ix )
mean_constraint_cVeg <- mean(Y_level1a_mean_cVeg_const[2, ] - Y_level1a_mean_cVeg_const[1, ])
Y_constraint_plot(Y_level1a_mean_cVeg_const,5,  main = paste('mean constrained range =', round(mean_constraint_cVeg,3)))

```

```{r}

# with 3 processers, using foreach parallel processing takes approximately 1/3 the time (around 20 seconds per emulator) of looping the emulator fitting directly. I'd hope this would scale with processor numbers - it'll be worth trying on SPICE.

# system.time(testloop_par <- direct_twoStep_glmnet_parallel(X=X_level1, Y = Y_level1))

```


## Writing robust, parallelised, multistart  emulators
```{r}
direct_twoStep_glmnet <- function(X, Y, ...){
  
  d <- ncol(Y)
  
  out <- vector(mode='list', length=d)
  
  for(i in 1:d){
    
    y <- Y[,i]
    
    em <- twoStep_glmnet(X=X, y = y, ...)
    out[i] <- em
 
  }
  
  out
} 


```


# Direct twoStep emulator using foreach
```{r}

library(doParallel)
registerDoParallel(cores = detectCores() - 1)

direct_twoStep_glmnet_parallel <- function(X, Y, ...){
  
  d <- ncol(Y)
  
  out <- vector(mode='list', length=d)
  
  foreach(i = 1:d) %dopar% {
    
    y <- Y[,i]
    
    em <- twoStep_glmnet(X=X, y = y, ...)
    out[i] <- em
 
  }
  
  out
} 

```



```{r}

# I actually wrote code to do this createKmFitList, which isn't parallel at the moment.
# Maybe make it parallel in the next version?

library(doParallel)
registerDoParallel(cores = detectCores() - 1)

direct_twoStep_glmnet_parallel <- function(X, Y, ...){
  
  d <- ncol(Y)
  foreach(i = 1:d) %dopar% {
    
    y <- Y[,i]
    
    em <- twoStep_glmnet(X=X, y = y, ...)
  }
} 



```



```{r}

library(doParallel)
cores=detectCores()
cl <- makeCluster(cores[1]-1) #not to overload your computer
registerDoParallel(cl)

fitlist_test <- createKmFitListParallel(X = X_level1a, Y =  Y_const_level1a_scaled, formula = ~., multistart = 4)
stopCluster(cl)

```

```{r, fig.width = 7, fig.height = 9}


plot(fitlist_test[[4]])
```


```{r}

#summariseKmLoo <- function(fit){
  
#  loo <- leaveOneOut.km(fit, type = 'UK', trend.reestim = TRUE)
  
#  loo_mean <- mean(loo$)
  
  
#}



```





```{r}

# system.time(testloop <- direct_twoStep_glmnet(X=X_level1, Y_level1))

```



```{r}
# Test parallel processing against a foreach processing (and maybe mclapply?)

#system.time(testloop_par <- direct_twoStep_glmnet_parallel(X=X_level1, Y_level1))



```


```{r}
emList <- function(X, Y){
  # Create a list of objects to be emulated
  # X             design matrix with (nrow) instances of (ncol) inputs
  # Y             matrix of outputs, with one row
  #               for each row of X

  d <- ncol(Y)
  em_list <- vector(mode='list', length=d)

  for(i in 1:d){
    em_obj <- NULL
    em_obj$X <- X
    em_obj$y <- Y[, i]
    em_list[[i]] <- em_obj
  }
  em_list
}
```

```{r}


#test <- emlist(X_level1, Y_level1)


```

```{r}

#mclapply(X = test, FUN = km)


```



```{r}

# function from hde for direct prediction
direct.pred = function (form, X, Y, Xnew, ...){
  # Directly applies km in parallel to predict each column of an ensemble
  ens.list = emlist(X = X, Y = Y)
  km.list = mclapply(ens.list, FUN = km.wrap, form = form)

  pred.list = mclapply(km.list, FUN = km.pred.wrap, Xnew = as.matrix(Xnew, nrow = 1), type = "UK")

  out.mean = sapply(pred.list, FUN=extract.predmean)
  out.sd = sapply(pred.list, FUN=extract.predsd)
  return(list(mean = out.mean, sd = out.sd))
}



```







